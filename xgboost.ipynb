{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "from typing import Tuple, List\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_parquet('data/train.parquet')\n",
    "test_df = pd.read_parquet('data/final_test.parquet')\n",
    "weather_df = pd.read_csv('external_data/external_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 496827 entries, 48321 to 929187\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   counter_id                 496827 non-null  category      \n",
      " 1   counter_name               496827 non-null  category      \n",
      " 2   site_id                    496827 non-null  int64         \n",
      " 3   site_name                  496827 non-null  category      \n",
      " 4   bike_count                 496827 non-null  float64       \n",
      " 5   date                       496827 non-null  datetime64[us]\n",
      " 6   counter_installation_date  496827 non-null  datetime64[us]\n",
      " 7   coordinates                496827 non-null  category      \n",
      " 8   counter_technical_id       496827 non-null  category      \n",
      " 9   latitude                   496827 non-null  float64       \n",
      " 10  longitude                  496827 non-null  float64       \n",
      " 11  log_bike_count             496827 non-null  float64       \n",
      "dtypes: category(5), datetime64[us](2), float64(4), int64(1)\n",
      "memory usage: 32.7 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51440 entries, 0 to 51439\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   counter_id                 51440 non-null  category      \n",
      " 1   counter_name               51440 non-null  category      \n",
      " 2   site_id                    51440 non-null  int64         \n",
      " 3   site_name                  51440 non-null  category      \n",
      " 4   date                       51440 non-null  datetime64[us]\n",
      " 5   counter_installation_date  51440 non-null  datetime64[us]\n",
      " 6   coordinates                51440 non-null  category      \n",
      " 7   counter_technical_id       51440 non-null  category      \n",
      " 8   latitude                   51440 non-null  float64       \n",
      " 9   longitude                  51440 non-null  float64       \n",
      "dtypes: category(5), datetime64[us](2), float64(2), int64(1)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3322 entries, 0 to 3321\n",
      "Data columns (total 59 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   numer_sta  3322 non-null   int64  \n",
      " 1   date       3322 non-null   object \n",
      " 2   pmer       3322 non-null   int64  \n",
      " 3   tend       3322 non-null   int64  \n",
      " 4   cod_tend   3322 non-null   int64  \n",
      " 5   dd         3322 non-null   int64  \n",
      " 6   ff         3322 non-null   float64\n",
      " 7   t          3322 non-null   float64\n",
      " 8   td         3322 non-null   float64\n",
      " 9   u          3322 non-null   int64  \n",
      " 10  vv         3322 non-null   int64  \n",
      " 11  ww         3322 non-null   int64  \n",
      " 12  w1         3315 non-null   float64\n",
      " 13  w2         3312 non-null   float64\n",
      " 14  n          3166 non-null   float64\n",
      " 15  nbas       3317 non-null   float64\n",
      " 16  hbas       2869 non-null   float64\n",
      " 17  cl         2909 non-null   float64\n",
      " 18  cm         1941 non-null   float64\n",
      " 19  ch         1678 non-null   float64\n",
      " 20  pres       3322 non-null   int64  \n",
      " 21  niv_bar    0 non-null      float64\n",
      " 22  geop       0 non-null      float64\n",
      " 23  tend24     3312 non-null   float64\n",
      " 24  tn12       830 non-null    float64\n",
      " 25  tn24       0 non-null      float64\n",
      " 26  tx12       830 non-null    float64\n",
      " 27  tx24       0 non-null      float64\n",
      " 28  tminsol    1 non-null      float64\n",
      " 29  sw         0 non-null      float64\n",
      " 30  tw         0 non-null      float64\n",
      " 31  raf10      3312 non-null   float64\n",
      " 32  rafper     3322 non-null   float64\n",
      " 33  per        3322 non-null   int64  \n",
      " 34  etat_sol   3270 non-null   float64\n",
      " 35  ht_neige   3273 non-null   float64\n",
      " 36  ssfrai     2877 non-null   float64\n",
      " 37  perssfrai  2877 non-null   float64\n",
      " 38  rr1        3313 non-null   float64\n",
      " 39  rr3        3316 non-null   float64\n",
      " 40  rr6        3306 non-null   float64\n",
      " 41  rr12       3300 non-null   float64\n",
      " 42  rr24       3298 non-null   float64\n",
      " 43  phenspe1   0 non-null      float64\n",
      " 44  phenspe2   0 non-null      float64\n",
      " 45  phenspe3   0 non-null      float64\n",
      " 46  phenspe4   0 non-null      float64\n",
      " 47  nnuage1    2873 non-null   float64\n",
      " 48  ctype1     2524 non-null   float64\n",
      " 49  hnuage1    2867 non-null   float64\n",
      " 50  nnuage2    1695 non-null   float64\n",
      " 51  ctype2     1443 non-null   float64\n",
      " 52  hnuage2    1695 non-null   float64\n",
      " 53  nnuage3    618 non-null    float64\n",
      " 54  ctype3     470 non-null    float64\n",
      " 55  hnuage3    618 non-null    float64\n",
      " 56  nnuage4    42 non-null     float64\n",
      " 57  ctype4     87 non-null     float64\n",
      " 58  hnuage4    42 non-null     float64\n",
      "dtypes: float64(48), int64(10), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "if 'bike_count' in train_df.columns:\n",
    "    train_df = train_df.drop(columns=['bike_count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 496827 entries, 48321 to 929187\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   counter_id                 496827 non-null  category      \n",
      " 1   counter_name               496827 non-null  category      \n",
      " 2   site_id                    496827 non-null  int64         \n",
      " 3   site_name                  496827 non-null  category      \n",
      " 4   date                       496827 non-null  datetime64[us]\n",
      " 5   counter_installation_date  496827 non-null  datetime64[us]\n",
      " 6   coordinates                496827 non-null  category      \n",
      " 7   counter_technical_id       496827 non-null  category      \n",
      " 8   latitude                   496827 non-null  float64       \n",
      " 9   longitude                  496827 non-null  float64       \n",
      " 10  log_bike_count             496827 non-null  float64       \n",
      "dtypes: category(5), datetime64[us](2), float64(3), int64(1)\n",
      "memory usage: 28.9 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            counter_id                       counter_name    site_id  \\\n",
      "0  100056329-104056329       Pont Charles De Gaulle NE-SO  100056329   \n",
      "1  100056334-104056334               38 rue Turbigo SO-NE  100056334   \n",
      "2  100047542-103047542  Face au 48 quai de la marne NE-SO  100047542   \n",
      "3  100057329-103057329   Totem 85 quai d'Austerlitz SE-NO  100057329   \n",
      "4  100047547-103047547           6 rue Julia Bartet SO-NE  100047547   \n",
      "\n",
      "                     site_name                date counter_installation_date  \\\n",
      "0       Pont Charles De Gaulle 2020-09-01 03:00:00                2019-12-12   \n",
      "1               38 rue Turbigo 2020-09-01 03:00:00                2019-12-10   \n",
      "2  Face au 48 quai de la marne 2020-09-01 03:00:00                2018-11-29   \n",
      "3   Totem 85 quai d'Austerlitz 2020-09-01 03:00:00                2020-02-18   \n",
      "4           6 rue Julia Bartet 2020-09-01 03:00:00                2018-11-28   \n",
      "\n",
      "        coordinates counter_technical_id  latitude  longitude  ...  hnuage1  \\\n",
      "0  48.84223,2.36811          Y2H19070375  48.84223    2.36811  ...      NaN   \n",
      "1  48.86502,2.35387          Y2H19070380  48.86502    2.35387  ...      NaN   \n",
      "2  48.89172,2.38531          Y2H18086318  48.89172    2.38531  ...      NaN   \n",
      "3  48.84201,2.36729          YTH19111508  48.84201    2.36729  ...      NaN   \n",
      "4  48.82636,2.30303          Y2H18086323  48.82636    2.30303  ...      NaN   \n",
      "\n",
      "   nnuage2  ctype2  hnuage2  nnuage3  ctype3  hnuage3  nnuage4  ctype4  \\\n",
      "0      NaN     NaN      NaN      NaN     NaN      NaN      NaN     NaN   \n",
      "1      NaN     NaN      NaN      NaN     NaN      NaN      NaN     NaN   \n",
      "2      NaN     NaN      NaN      NaN     NaN      NaN      NaN     NaN   \n",
      "3      NaN     NaN      NaN      NaN     NaN      NaN      NaN     NaN   \n",
      "4      NaN     NaN      NaN      NaN     NaN      NaN      NaN     NaN   \n",
      "\n",
      "   hnuage4  \n",
      "0      NaN  \n",
      "1      NaN  \n",
      "2      NaN  \n",
      "3      NaN  \n",
      "4      NaN  \n",
      "\n",
      "[5 rows x 69 columns]\n",
      "            counter_id                                     counter_name  \\\n",
      "0  100007049-102007049                         28 boulevard Diderot E-O   \n",
      "1  300014702-353245971                       254 rue de Vaugirard SO-NE   \n",
      "2  100050876-103050876                       Totem 64 Rue de Rivoli E-O   \n",
      "3  100056226-104056226  Face au 8 avenue de la porte de Charenton NO-SE   \n",
      "4  100056331-104056331                     Face au 40 quai D'Issy NE-SO   \n",
      "\n",
      "     site_id                                  site_name                date  \\\n",
      "0  100007049                       28 boulevard Diderot 2021-09-10 03:00:00   \n",
      "1  300014702                       254 rue de Vaugirard 2021-09-10 03:00:00   \n",
      "2  100050876                     Totem 64 Rue de Rivoli 2021-09-10 03:00:00   \n",
      "3  100056226  Face au 8 avenue de la porte de Charenton 2021-09-10 03:00:00   \n",
      "4  100056331                     Face au 40 quai D'Issy 2021-09-10 03:00:00   \n",
      "\n",
      "  counter_installation_date         coordinates counter_technical_id  \\\n",
      "0                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "1                2020-11-29    48.83977,2.30198          Y2H20114504   \n",
      "2                2019-09-04    48.85735,2.35211          YTH19037970   \n",
      "3                2019-11-01  48.830331,2.400551          Y2H19070370   \n",
      "4                2019-11-05    48.83421,2.26542          Y2H19070377   \n",
      "\n",
      "    latitude  longitude  ...  hnuage1  nnuage2  ctype2  hnuage2  nnuage3  \\\n",
      "0  48.846028   2.375429  ...    260.0      7.0     6.0   1980.0      NaN   \n",
      "1  48.839770   2.301980  ...    260.0      7.0     6.0   1980.0      NaN   \n",
      "2  48.857350   2.352110  ...    260.0      7.0     6.0   1980.0      NaN   \n",
      "3  48.830331   2.400551  ...    260.0      7.0     6.0   1980.0      NaN   \n",
      "4  48.834210   2.265420  ...    260.0      7.0     6.0   1980.0      NaN   \n",
      "\n",
      "   ctype3  hnuage3  nnuage4  ctype4  hnuage4  \n",
      "0     NaN      NaN      NaN     NaN      NaN  \n",
      "1     NaN      NaN      NaN     NaN      NaN  \n",
      "2     NaN      NaN      NaN     NaN      NaN  \n",
      "3     NaN      NaN      NaN     NaN      NaN  \n",
      "4     NaN      NaN      NaN     NaN      NaN  \n",
      "\n",
      "[5 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess weather data\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date']).astype('datetime64[ns]')\n",
    "weather_df.sort_values('date', inplace=True)\n",
    "\n",
    "# Preprocess train data\n",
    "train_df['date'] = pd.to_datetime(train_df['date']).astype('datetime64[ns]')\n",
    "train_df.sort_values('date', inplace=True)\n",
    "\n",
    "test_df['date'] = pd.to_datetime(test_df['date']).astype('datetime64[ns]')\n",
    "test_df.sort_values('date', inplace=True)\n",
    "\n",
    "merged_df_train = pd.merge(train_df, weather_df, on='date', how= 'inner')\n",
    "merged_df_test = pd.merge(test_df, weather_df, on='date', how='inner')\n",
    "\n",
    "print(merged_df_train.head(5))\n",
    "print(merged_df_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 165368 entries, 0 to 165367\n",
      "Data columns (total 69 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   counter_id                 165368 non-null  category      \n",
      " 1   counter_name               165368 non-null  category      \n",
      " 2   site_id                    165368 non-null  int64         \n",
      " 3   site_name                  165368 non-null  category      \n",
      " 4   date                       165368 non-null  datetime64[ns]\n",
      " 5   counter_installation_date  165368 non-null  datetime64[us]\n",
      " 6   coordinates                165368 non-null  category      \n",
      " 7   counter_technical_id       165368 non-null  category      \n",
      " 8   latitude                   165368 non-null  float64       \n",
      " 9   longitude                  165368 non-null  float64       \n",
      " 10  log_bike_count             165368 non-null  float64       \n",
      " 11  numer_sta                  165368 non-null  int64         \n",
      " 12  pmer                       165368 non-null  int64         \n",
      " 13  tend                       165368 non-null  int64         \n",
      " 14  cod_tend                   165368 non-null  int64         \n",
      " 15  dd                         165368 non-null  int64         \n",
      " 16  ff                         165368 non-null  float64       \n",
      " 17  t                          165368 non-null  float64       \n",
      " 18  td                         165368 non-null  float64       \n",
      " 19  u                          165368 non-null  int64         \n",
      " 20  vv                         165368 non-null  int64         \n",
      " 21  ww                         165368 non-null  int64         \n",
      " 22  w1                         164980 non-null  float64       \n",
      " 23  w2                         164816 non-null  float64       \n",
      " 24  n                          157746 non-null  float64       \n",
      " 25  nbas                       165090 non-null  float64       \n",
      " 26  hbas                       142648 non-null  float64       \n",
      " 27  cl                         144856 non-null  float64       \n",
      " 28  cm                         94304 non-null   float64       \n",
      " 29  ch                         80950 non-null   float64       \n",
      " 30  pres                       165368 non-null  int64         \n",
      " 31  niv_bar                    0 non-null       float64       \n",
      " 32  geop                       0 non-null       float64       \n",
      " 33  tend24                     164812 non-null  float64       \n",
      " 34  tn12                       41352 non-null   float64       \n",
      " 35  tn24                       0 non-null       float64       \n",
      " 36  tx12                       41352 non-null   float64       \n",
      " 37  tx24                       0 non-null       float64       \n",
      " 38  tminsol                    56 non-null      float64       \n",
      " 39  sw                         0 non-null       float64       \n",
      " 40  tw                         0 non-null       float64       \n",
      " 41  raf10                      164812 non-null  float64       \n",
      " 42  rafper                     165368 non-null  float64       \n",
      " 43  per                        165368 non-null  int64         \n",
      " 44  etat_sol                   162652 non-null  float64       \n",
      " 45  ht_neige                   162916 non-null  float64       \n",
      " 46  ssfrai                     143066 non-null  float64       \n",
      " 47  perssfrai                  143066 non-null  float64       \n",
      " 48  rr1                        164920 non-null  float64       \n",
      " 49  rr3                        165144 non-null  float64       \n",
      " 50  rr6                        164700 non-null  float64       \n",
      " 51  rr12                       164476 non-null  float64       \n",
      " 52  rr24                       164364 non-null  float64       \n",
      " 53  phenspe1                   0 non-null       float64       \n",
      " 54  phenspe2                   0 non-null       float64       \n",
      " 55  phenspe3                   0 non-null       float64       \n",
      " 56  phenspe4                   0 non-null       float64       \n",
      " 57  nnuage1                    142866 non-null  float64       \n",
      " 58  ctype1                     125500 non-null  float64       \n",
      " 59  hnuage1                    142536 non-null  float64       \n",
      " 60  nnuage2                    84208 non-null   float64       \n",
      " 61  ctype2                     71770 non-null   float64       \n",
      " 62  hnuage2                    84208 non-null   float64       \n",
      " 63  nnuage3                    30064 non-null   float64       \n",
      " 64  ctype3                     22756 non-null   float64       \n",
      " 65  hnuage3                    30064 non-null   float64       \n",
      " 66  nnuage4                    1890 non-null    float64       \n",
      " 67  ctype4                     4112 non-null    float64       \n",
      " 68  hnuage4                    1890 non-null    float64       \n",
      "dtypes: category(5), datetime64[ns](1), datetime64[us](1), float64(51), int64(11)\n",
      "memory usage: 81.5 MB\n"
     ]
    }
   ],
   "source": [
    "merged_df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17148 entries, 0 to 17147\n",
      "Data columns (total 68 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   counter_id                 17148 non-null  category      \n",
      " 1   counter_name               17148 non-null  category      \n",
      " 2   site_id                    17148 non-null  int64         \n",
      " 3   site_name                  17148 non-null  category      \n",
      " 4   date                       17148 non-null  datetime64[ns]\n",
      " 5   counter_installation_date  17148 non-null  datetime64[us]\n",
      " 6   coordinates                17148 non-null  category      \n",
      " 7   counter_technical_id       17148 non-null  category      \n",
      " 8   latitude                   17148 non-null  float64       \n",
      " 9   longitude                  17148 non-null  float64       \n",
      " 10  numer_sta                  17148 non-null  int64         \n",
      " 11  pmer                       17148 non-null  int64         \n",
      " 12  tend                       17148 non-null  int64         \n",
      " 13  cod_tend                   17148 non-null  int64         \n",
      " 14  dd                         17148 non-null  int64         \n",
      " 15  ff                         17148 non-null  float64       \n",
      " 16  t                          17148 non-null  float64       \n",
      " 17  td                         17148 non-null  float64       \n",
      " 18  u                          17148 non-null  int64         \n",
      " 19  vv                         17148 non-null  int64         \n",
      " 20  ww                         17148 non-null  int64         \n",
      " 21  w1                         17148 non-null  float64       \n",
      " 22  w2                         17148 non-null  float64       \n",
      " 23  n                          16165 non-null  float64       \n",
      " 24  nbas                       17148 non-null  float64       \n",
      " 25  hbas                       14825 non-null  float64       \n",
      " 26  cl                         15067 non-null  float64       \n",
      " 27  cm                         12325 non-null  float64       \n",
      " 28  ch                         11395 non-null  float64       \n",
      " 29  pres                       17148 non-null  int64         \n",
      " 30  niv_bar                    0 non-null      float64       \n",
      " 31  geop                       0 non-null      float64       \n",
      " 32  tend24                     17148 non-null  float64       \n",
      " 33  tn12                       4302 non-null   float64       \n",
      " 34  tn24                       0 non-null      float64       \n",
      " 35  tx12                       4302 non-null   float64       \n",
      " 36  tx24                       0 non-null      float64       \n",
      " 37  tminsol                    0 non-null      float64       \n",
      " 38  sw                         0 non-null      float64       \n",
      " 39  tw                         0 non-null      float64       \n",
      " 40  raf10                      17148 non-null  float64       \n",
      " 41  rafper                     17148 non-null  float64       \n",
      " 42  per                        17148 non-null  int64         \n",
      " 43  etat_sol                   16982 non-null  float64       \n",
      " 44  ht_neige                   16928 non-null  float64       \n",
      " 45  ssfrai                     15067 non-null  float64       \n",
      " 46  perssfrai                  15067 non-null  float64       \n",
      " 47  rr1                        17093 non-null  float64       \n",
      " 48  rr3                        17093 non-null  float64       \n",
      " 49  rr6                        17038 non-null  float64       \n",
      " 50  rr12                       16928 non-null  float64       \n",
      " 51  rr24                       16928 non-null  float64       \n",
      " 52  phenspe1                   0 non-null      float64       \n",
      " 53  phenspe2                   0 non-null      float64       \n",
      " 54  phenspe3                   0 non-null      float64       \n",
      " 55  phenspe4                   0 non-null      float64       \n",
      " 56  nnuage1                    14825 non-null  float64       \n",
      " 57  ctype1                     13126 non-null  float64       \n",
      " 58  hnuage1                    14825 non-null  float64       \n",
      " 59  nnuage2                    8654 non-null   float64       \n",
      " 60  ctype2                     7390 non-null   float64       \n",
      " 61  hnuage2                    8654 non-null   float64       \n",
      " 62  nnuage3                    3911 non-null   float64       \n",
      " 63  ctype3                     3142 non-null   float64       \n",
      " 64  hnuage3                    3911 non-null   float64       \n",
      " 65  nnuage4                    435 non-null    float64       \n",
      " 66  ctype4                     654 non-null    float64       \n",
      " 67  hnuage4                    435 non-null    float64       \n",
      "dtypes: category(5), datetime64[ns](1), datetime64[us](1), float64(50), int64(11)\n",
      "memory usage: 8.3 MB\n"
     ]
    }
   ],
   "source": [
    "merged_df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "            counter_id                       counter_name    site_id  \\\n",
      "0  100056329-104056329       Pont Charles De Gaulle NE-SO  100056329   \n",
      "1  100056334-104056334               38 rue Turbigo SO-NE  100056334   \n",
      "2  100047542-103047542  Face au 48 quai de la marne NE-SO  100047542   \n",
      "3  100057329-103057329   Totem 85 quai d'Austerlitz SE-NO  100057329   \n",
      "4  100047547-103047547           6 rue Julia Bartet SO-NE  100047547   \n",
      "\n",
      "                     site_name                date counter_installation_date  \\\n",
      "0       Pont Charles De Gaulle 2020-09-01 03:00:00                2019-12-12   \n",
      "1               38 rue Turbigo 2020-09-01 03:00:00                2019-12-10   \n",
      "2  Face au 48 quai de la marne 2020-09-01 03:00:00                2018-11-29   \n",
      "3   Totem 85 quai d'Austerlitz 2020-09-01 03:00:00                2020-02-18   \n",
      "4           6 rue Julia Bartet 2020-09-01 03:00:00                2018-11-28   \n",
      "\n",
      "        coordinates counter_technical_id  latitude  longitude  ...  hnuage1  \\\n",
      "0  48.84223,2.36811          Y2H19070375  48.84223    2.36811  ...      NaN   \n",
      "1  48.86502,2.35387          Y2H19070380  48.86502    2.35387  ...      NaN   \n",
      "2  48.89172,2.38531          Y2H18086318  48.89172    2.38531  ...      NaN   \n",
      "3  48.84201,2.36729          YTH19111508  48.84201    2.36729  ...      NaN   \n",
      "4  48.82636,2.30303          Y2H18086323  48.82636    2.30303  ...      NaN   \n",
      "\n",
      "   nnuage2  ctype2  hnuage2  nnuage3  ctype3  hnuage3  nnuage4  ctype4  \\\n",
      "0      NaN     NaN      NaN      NaN     NaN      NaN      NaN     NaN   \n",
      "1      NaN     NaN      NaN      NaN     NaN      NaN      NaN     NaN   \n",
      "2      NaN     NaN      NaN      NaN     NaN      NaN      NaN     NaN   \n",
      "3      NaN     NaN      NaN      NaN     NaN      NaN      NaN     NaN   \n",
      "4      NaN     NaN      NaN      NaN     NaN      NaN      NaN     NaN   \n",
      "\n",
      "   hnuage4  \n",
      "0      NaN  \n",
      "1      NaN  \n",
      "2      NaN  \n",
      "3      NaN  \n",
      "4      NaN  \n",
      "\n",
      "[5 rows x 69 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "            counter_id                                     counter_name  \\\n",
      "0  100007049-102007049                         28 boulevard Diderot E-O   \n",
      "1  300014702-353245971                       254 rue de Vaugirard SO-NE   \n",
      "2  100050876-103050876                       Totem 64 Rue de Rivoli E-O   \n",
      "3  100056226-104056226  Face au 8 avenue de la porte de Charenton NO-SE   \n",
      "4  100056331-104056331                     Face au 40 quai D'Issy NE-SO   \n",
      "\n",
      "     site_id                                  site_name                date  \\\n",
      "0  100007049                       28 boulevard Diderot 2021-09-10 03:00:00   \n",
      "1  300014702                       254 rue de Vaugirard 2021-09-10 03:00:00   \n",
      "2  100050876                     Totem 64 Rue de Rivoli 2021-09-10 03:00:00   \n",
      "3  100056226  Face au 8 avenue de la porte de Charenton 2021-09-10 03:00:00   \n",
      "4  100056331                     Face au 40 quai D'Issy 2021-09-10 03:00:00   \n",
      "\n",
      "  counter_installation_date         coordinates counter_technical_id  \\\n",
      "0                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
      "1                2020-11-29    48.83977,2.30198          Y2H20114504   \n",
      "2                2019-09-04    48.85735,2.35211          YTH19037970   \n",
      "3                2019-11-01  48.830331,2.400551          Y2H19070370   \n",
      "4                2019-11-05    48.83421,2.26542          Y2H19070377   \n",
      "\n",
      "    latitude  longitude  ...  hnuage1  nnuage2  ctype2  hnuage2  nnuage3  \\\n",
      "0  48.846028   2.375429  ...    260.0      7.0     6.0   1980.0      NaN   \n",
      "1  48.839770   2.301980  ...    260.0      7.0     6.0   1980.0      NaN   \n",
      "2  48.857350   2.352110  ...    260.0      7.0     6.0   1980.0      NaN   \n",
      "3  48.830331   2.400551  ...    260.0      7.0     6.0   1980.0      NaN   \n",
      "4  48.834210   2.265420  ...    260.0      7.0     6.0   1980.0      NaN   \n",
      "\n",
      "   ctype3  hnuage3  nnuage4  ctype4  hnuage4  \n",
      "0     NaN      NaN      NaN     NaN      NaN  \n",
      "1     NaN      NaN      NaN     NaN      NaN  \n",
      "2     NaN      NaN      NaN     NaN      NaN  \n",
      "3     NaN      NaN      NaN     NaN      NaN  \n",
      "4     NaN      NaN      NaN     NaN      NaN  \n",
      "\n",
      "[5 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "print(type(merged_df_train))\n",
    "print(merged_df_train.head())\n",
    "print(type(merged_df_test))\n",
    "print(merged_df_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['counter_id', 'counter_name', 'site_id', 'site_name', 'date',\n",
      "       'counter_installation_date', 'coordinates', 'counter_technical_id',\n",
      "       'latitude', 'longitude', 'log_bike_count', 'numer_sta', 'pmer', 'tend',\n",
      "       'cod_tend', 'dd', 'ff', 't', 'td', 'u', 'vv', 'ww', 'w1', 'w2', 'n',\n",
      "       'nbas', 'hbas', 'cl', 'cm', 'ch', 'pres', 'niv_bar', 'geop', 'tend24',\n",
      "       'tn12', 'tn24', 'tx12', 'tx24', 'tminsol', 'sw', 'tw', 'raf10',\n",
      "       'rafper', 'per', 'etat_sol', 'ht_neige', 'ssfrai', 'perssfrai', 'rr1',\n",
      "       'rr3', 'rr6', 'rr12', 'rr24', 'phenspe1', 'phenspe2', 'phenspe3',\n",
      "       'phenspe4', 'nnuage1', 'ctype1', 'hnuage1', 'nnuage2', 'ctype2',\n",
      "       'hnuage2', 'nnuage3', 'ctype3', 'hnuage3', 'nnuage4', 'ctype4',\n",
      "       'hnuage4'],\n",
      "      dtype='object')\n",
      "Index(['counter_id', 'counter_name', 'site_id', 'site_name', 'date',\n",
      "       'counter_installation_date', 'coordinates', 'counter_technical_id',\n",
      "       'latitude', 'longitude', 'numer_sta', 'pmer', 'tend', 'cod_tend', 'dd',\n",
      "       'ff', 't', 'td', 'u', 'vv', 'ww', 'w1', 'w2', 'n', 'nbas', 'hbas', 'cl',\n",
      "       'cm', 'ch', 'pres', 'niv_bar', 'geop', 'tend24', 'tn12', 'tn24', 'tx12',\n",
      "       'tx24', 'tminsol', 'sw', 'tw', 'raf10', 'rafper', 'per', 'etat_sol',\n",
      "       'ht_neige', 'ssfrai', 'perssfrai', 'rr1', 'rr3', 'rr6', 'rr12', 'rr24',\n",
      "       'phenspe1', 'phenspe2', 'phenspe3', 'phenspe4', 'nnuage1', 'ctype1',\n",
      "       'hnuage1', 'nnuage2', 'ctype2', 'hnuage2', 'nnuage3', 'ctype3',\n",
      "       'hnuage3', 'nnuage4', 'ctype4', 'hnuage4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_df_train.columns)\n",
    "print(merged_df_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Drop irrelevant columns\n",
    "irrelevant_columns = [\n",
    "    'counter_id', 'counter_name', 'site_id', 'site_name', 'coordinates', \n",
    "    'counter_technical_id', 'latitude', 'longitude', 'counter_installation_date', \n",
    "    'numer_sta', 'niv_bar', 'geop', 'tn24', 'tx24', 'sw', 'tw', 'phenspe1', 'phenspe2', 'phenspe3', 'phenspe4'\n",
    "]\n",
    "merged_df_train.drop(columns=irrelevant_columns, inplace=True)\n",
    "merged_df_test.drop(columns=irrelevant_columns, inplace=True)\n",
    "\n",
    "print(type(merged_df_train))\n",
    "print(type(merged_df_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing data\n",
    "# Drop columns with more than 50% missing values\n",
    "threshold = 0.5 * len(merged_df_train)\n",
    "merged_df_train.dropna(axis=1, thresh=threshold, inplace=True)\n",
    "#merged_df_test = merged_df_test.drop(columns=[col for col in merged_df_test.columns if col not in merged_df_train.columns], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'log_bike_count', 'pmer', 'tend', 'cod_tend', 'dd', 'ff', 't',\n",
      "       'td', 'u', 'vv', 'ww', 'w1', 'w2', 'n', 'nbas', 'hbas', 'cl', 'cm',\n",
      "       'pres', 'tend24', 'raf10', 'rafper', 'per', 'etat_sol', 'ht_neige',\n",
      "       'ssfrai', 'perssfrai', 'rr1', 'rr3', 'rr6', 'rr12', 'rr24', 'nnuage1',\n",
      "       'ctype1', 'hnuage1', 'nnuage2', 'hnuage2'],\n",
      "      dtype='object')\n",
      "Index(['date', 'pmer', 'tend', 'cod_tend', 'dd', 'ff', 't', 'td', 'u', 'vv',\n",
      "       'ww', 'w1', 'w2', 'n', 'nbas', 'hbas', 'cl', 'cm', 'ch', 'pres',\n",
      "       'tend24', 'tn12', 'tx12', 'tminsol', 'raf10', 'rafper', 'per',\n",
      "       'etat_sol', 'ht_neige', 'ssfrai', 'perssfrai', 'rr1', 'rr3', 'rr6',\n",
      "       'rr12', 'rr24', 'nnuage1', 'ctype1', 'hnuage1', 'nnuage2', 'ctype2',\n",
      "       'hnuage2', 'nnuage3', 'ctype3', 'hnuage3', 'nnuage4', 'ctype4',\n",
      "       'hnuage4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_df_train.columns)\n",
    "print(merged_df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 165368 entries, 0 to 165367\n",
      "Data columns (total 38 columns):\n",
      " #   Column          Non-Null Count   Dtype         \n",
      "---  ------          --------------   -----         \n",
      " 0   date            165368 non-null  datetime64[ns]\n",
      " 1   log_bike_count  165368 non-null  float64       \n",
      " 2   pmer            165368 non-null  int64         \n",
      " 3   tend            165368 non-null  int64         \n",
      " 4   cod_tend        165368 non-null  int64         \n",
      " 5   dd              165368 non-null  int64         \n",
      " 6   ff              165368 non-null  float64       \n",
      " 7   t               165368 non-null  float64       \n",
      " 8   td              165368 non-null  float64       \n",
      " 9   u               165368 non-null  int64         \n",
      " 10  vv              165368 non-null  int64         \n",
      " 11  ww              165368 non-null  int64         \n",
      " 12  w1              164980 non-null  float64       \n",
      " 13  w2              164816 non-null  float64       \n",
      " 14  n               157746 non-null  float64       \n",
      " 15  nbas            165090 non-null  float64       \n",
      " 16  hbas            142648 non-null  float64       \n",
      " 17  cl              144856 non-null  float64       \n",
      " 18  cm              94304 non-null   float64       \n",
      " 19  pres            165368 non-null  int64         \n",
      " 20  tend24          164812 non-null  float64       \n",
      " 21  raf10           164812 non-null  float64       \n",
      " 22  rafper          165368 non-null  float64       \n",
      " 23  per             165368 non-null  int64         \n",
      " 24  etat_sol        162652 non-null  float64       \n",
      " 25  ht_neige        162916 non-null  float64       \n",
      " 26  ssfrai          143066 non-null  float64       \n",
      " 27  perssfrai       143066 non-null  float64       \n",
      " 28  rr1             164920 non-null  float64       \n",
      " 29  rr3             165144 non-null  float64       \n",
      " 30  rr6             164700 non-null  float64       \n",
      " 31  rr12            164476 non-null  float64       \n",
      " 32  rr24            164364 non-null  float64       \n",
      " 33  nnuage1         142866 non-null  float64       \n",
      " 34  ctype1          125500 non-null  float64       \n",
      " 35  hnuage1         142536 non-null  float64       \n",
      " 36  nnuage2         84208 non-null   float64       \n",
      " 37  hnuage2         84208 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(28), int64(9)\n",
      "memory usage: 47.9 MB\n"
     ]
    }
   ],
   "source": [
    "merged_df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_test.drop(columns=[col for col in merged_df_test.columns if col not in merged_df_train.columns], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17148 entries, 0 to 17147\n",
      "Data columns (total 37 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   date       17148 non-null  datetime64[ns]\n",
      " 1   pmer       17148 non-null  int64         \n",
      " 2   tend       17148 non-null  int64         \n",
      " 3   cod_tend   17148 non-null  int64         \n",
      " 4   dd         17148 non-null  int64         \n",
      " 5   ff         17148 non-null  float64       \n",
      " 6   t          17148 non-null  float64       \n",
      " 7   td         17148 non-null  float64       \n",
      " 8   u          17148 non-null  int64         \n",
      " 9   vv         17148 non-null  int64         \n",
      " 10  ww         17148 non-null  int64         \n",
      " 11  w1         17148 non-null  float64       \n",
      " 12  w2         17148 non-null  float64       \n",
      " 13  n          16165 non-null  float64       \n",
      " 14  nbas       17148 non-null  float64       \n",
      " 15  hbas       14825 non-null  float64       \n",
      " 16  cl         15067 non-null  float64       \n",
      " 17  cm         12325 non-null  float64       \n",
      " 18  pres       17148 non-null  int64         \n",
      " 19  tend24     17148 non-null  float64       \n",
      " 20  raf10      17148 non-null  float64       \n",
      " 21  rafper     17148 non-null  float64       \n",
      " 22  per        17148 non-null  int64         \n",
      " 23  etat_sol   16982 non-null  float64       \n",
      " 24  ht_neige   16928 non-null  float64       \n",
      " 25  ssfrai     15067 non-null  float64       \n",
      " 26  perssfrai  15067 non-null  float64       \n",
      " 27  rr1        17093 non-null  float64       \n",
      " 28  rr3        17093 non-null  float64       \n",
      " 29  rr6        17038 non-null  float64       \n",
      " 30  rr12       16928 non-null  float64       \n",
      " 31  rr24       16928 non-null  float64       \n",
      " 32  nnuage1    14825 non-null  float64       \n",
      " 33  ctype1     13126 non-null  float64       \n",
      " 34  hnuage1    14825 non-null  float64       \n",
      " 35  nnuage2    8654 non-null   float64       \n",
      " 36  hnuage2    8654 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(27), int64(9)\n",
      "memory usage: 4.8 MB\n"
     ]
    }
   ],
   "source": [
    "merged_df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'log_bike_count', 'pmer', 'tend', 'cod_tend', 'dd', 'ff', 't',\n",
      "       'td', 'u', 'vv', 'ww', 'w1', 'w2', 'n', 'nbas', 'hbas', 'cl', 'cm',\n",
      "       'pres', 'tend24', 'raf10', 'rafper', 'per', 'etat_sol', 'ht_neige',\n",
      "       'ssfrai', 'perssfrai', 'rr1', 'rr3', 'rr6', 'rr12', 'rr24', 'nnuage1',\n",
      "       'ctype1', 'hnuage1', 'nnuage2', 'hnuage2', 'day_of_week', 'month',\n",
      "       'day_of_year', 'is_holiday'],\n",
      "      dtype='object')\n",
      "Index(['date', 'pmer', 'tend', 'cod_tend', 'dd', 'ff', 't', 'td', 'u', 'vv',\n",
      "       'ww', 'w1', 'w2', 'n', 'nbas', 'hbas', 'cl', 'cm', 'pres', 'tend24',\n",
      "       'raf10', 'rafper', 'per', 'etat_sol', 'ht_neige', 'ssfrai', 'perssfrai',\n",
      "       'rr1', 'rr3', 'rr6', 'rr12', 'rr24', 'nnuage1', 'ctype1', 'hnuage1',\n",
      "       'nnuage2', 'hnuage2', 'day_of_week', 'month', 'day_of_year',\n",
      "       'is_holiday'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def add_additional_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add additional features like day of week, month, day of year, and holiday indicator.\n",
    "    \"\"\"\n",
    "    # Convert 'date' column to datetime if not already in datetime format\n",
    "    if not np.issubdtype(df['date'].dtype, np.datetime64):\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Date-based features\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "\n",
    "    # Holiday indicator feature (Example: US Holidays)\n",
    "    us_holidays = holidays.US(years=2023)  # Adjust the year as needed\n",
    "    df['is_holiday'] = df['date'].dt.date.isin(us_holidays.keys())\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering to train and test data\n",
    "merged_df_train = add_additional_features(merged_df_train)\n",
    "merged_df_test = add_additional_features(merged_df_test)\n",
    "\n",
    "print(merged_df_train.columns)\n",
    "print(merged_df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "def build_optimized_pipeline(X: pd.DataFrame) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Build an optimized pipeline with advanced preprocessing and ensemble models.\n",
    "    \"\"\"\n",
    "    # Separate features into numerical and categorical\n",
    "    selected_features_numeric = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "    selected_features_categorical = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    # Numeric transformer with scaling and imputation\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing values\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Categorical transformer with imputation and one-hot encoding\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),  # Handle missing values\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Preprocessor with column transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, selected_features_numeric),\n",
    "            ('cat', categorical_transformer, selected_features_categorical)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Feature selection using mutual information regression\n",
    "    feature_selection = SelectKBest(score_func=mutual_info_regression, k=10)\n",
    "\n",
    "    # Stacked regressor with XGBoost and Random Forest\n",
    "    stacked_model = StackingRegressor(\n",
    "        estimators=[\n",
    "            ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "            ('xgb', xgb.XGBRegressor(\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=4,\n",
    "                random_state=42))\n",
    "        ],\n",
    "        final_estimator=xgb.XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=3,\n",
    "            random_state=42)\n",
    "    )\n",
    "\n",
    "    # Final pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('feature_selection', feature_selection),\n",
    "        ('regressor', stacked_model)\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def evaluate_pipeline(pipeline: Pipeline, X: pd.DataFrame, y: pd.Series) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Evaluate pipeline performance using various metrics.\n",
    "    \"\"\"\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
    "\n",
    "    # Output results\n",
    "    print(\"Model Evaluation Metrics:\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mse):.4f}\")\n",
    "    print(f\"R-squared Score (R²): {r2:.4f}\")\n",
    "    print(\"Cross-validation R² scores:\", cv_scores)\n",
    "    print(f\"Mean CV R² score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def predict_test_data(pipeline: Pipeline, test_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate predictions for test data.\n",
    "    \"\"\"\n",
    "    predictions = pipeline.predict(test_data)\n",
    "    return pd.DataFrame({\n",
    "        'Id': range(len(predictions)),\n",
    "        'log_bike_count': predictions\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure target variable exists in training data\n",
    "if 'log_bike_count' not in merged_df_train.columns:\n",
    "    raise ValueError(\"'log_bike_count' is missing in the training data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics:\n",
      "Root Mean Squared Error (RMSE): 0.9288\n",
      "R-squared Score (R²): 0.6853\n",
      "Cross-validation R² scores: [ 0.08115468 -0.05751698  0.11307078  0.20331312  0.16847639]\n",
      "Mean CV R² score: 0.1017 (+/- 0.1804)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "target_col = 'log_bike_count'\n",
    "X = merged_df_train.drop(columns=[target_col])\n",
    "y = merged_df_train[target_col]\n",
    "\n",
    "# Build pipeline\n",
    "pipeline = build_optimized_pipeline(X)\n",
    "\n",
    "# Evaluate pipeline\n",
    "pipeline = evaluate_pipeline(pipeline, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prin' is not defined"
     ]
    }
   ],
   "source": [
    "prin(\"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = merged_df_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = merged_df_train.select_dtypes(include=['category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_pipeline(X: pd.DataFrame) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Construct ML pipeline with preprocessing and XGBoost.\n",
    "    \"\"\"\n",
    "    # Separate features into numerical and categorical\n",
    "    selected_features_numeric = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "    selected_features_categorical = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    # Numeric transformer with scaling and imputation\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # Handle missing values\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Categorical transformer with imputation and one-hot encoding\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Handle missing values\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Preprocessor with column transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, selected_features_numeric),\n",
    "            ('cat', categorical_transformer, selected_features_categorical)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Final pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('feature_selection', SelectKBest(score_func=f_regression, k=20)),\n",
    "        ('regressor', xgb.XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=4,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def evaluate_model(pipeline: Pipeline, X: pd.DataFrame, y: pd.Series) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Evaluate model performance using various metrics.\n",
    "    \"\"\"\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
    "\n",
    "    # Output results\n",
    "    print(\"Model Evaluation Metrics:\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mse):.4f}\")\n",
    "    print(f\"R-squared Score (R²): {r2:.4f}\")\n",
    "    print(\"Cross-validation R² scores:\", cv_scores)\n",
    "    print(f\"Mean CV R² score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def predict(pipeline: Pipeline, test_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate predictions for test data.\n",
    "    \"\"\"\n",
    "    predictions = pipeline.predict(test_data)\n",
    "    return pd.DataFrame({\n",
    "        'Id': range(len(predictions)),\n",
    "        'log_bike_count': predictions\n",
    "    })\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics:\n",
      "Root Mean Squared Error (RMSE): 1.1840\n",
      "R-squared Score (R²): 0.4899\n",
      "Cross-validation R² scores: [ 0.19460499 -0.11880227  0.15578018  0.20220097  0.20338955]\n",
      "Mean CV R² score: 0.1274 (+/- 0.2487)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "target_col = 'log_bike_count'\n",
    "X = merged_df_train.drop(columns=[target_col])\n",
    "y = merged_df_train[target_col]\n",
    "\n",
    "# Build pipeline\n",
    "pipeline = build_model_pipeline(X)\n",
    "\n",
    "# Evaluate pipeline\n",
    "pipeline = evaluate_model(pipeline, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align test data columns with training data\n",
    "test_X = merged_df_test[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as 'submission.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Generate submission file\n",
    "submission = predict(pipeline, test_X)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved as 'submission.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
